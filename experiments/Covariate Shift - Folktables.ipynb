{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a314e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09fe74ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as p\n",
    "from sklearn.linear_model import QuantileRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from folktables import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b1e71e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71747913",
   "metadata": {},
   "source": [
    "## Folktables data\n",
    "\n",
    "NOTE: please unzip file ./data/2018.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66fae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACSIncomeNew = folktables.BasicProblem(\n",
    "    features=[\n",
    "        'COW',\n",
    "        'SCHL',\n",
    "        'MAR',\n",
    "        'OCCP',\n",
    "        'POBP',\n",
    "        'RELP',\n",
    "        'WKHP',\n",
    "        'SEX',\n",
    "        'RAC1P',\n",
    "    ],\n",
    "    target='PINCP',\n",
    "    group='SEX',\n",
    "    preprocess=adult_filter,\n",
    "    postprocess=lambda x: np.nan_to_num(x, -1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199fbee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_folk_data(state_one, state_two ):\n",
    "    data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "    ca_data = data_source.get_data(states=[state_one], download=True)\n",
    "    ca_features, ca_label, ca_group = ACSIncomeNew.df_to_numpy(ca_data)\n",
    "    pa_data = data_source.get_data(states=[state_two], download=True)\n",
    "    pa_features, pa_label, pa_group = ACSIncomeNew.df_to_numpy(pa_data)\n",
    "    X_ls, X_calibrate, y_ls, y_calibrate = train_test_split(ca_features, ca_label, test_size=0.6, random_state=0)\n",
    "    X_eval, X_eval2, y_eval, y_eval2 = train_test_split(pa_features, pa_label, test_size=0.6, random_state=0)\n",
    "\n",
    "    # taking .2 of entire dataset for each fold for time\n",
    "    X_ls, X_calibrate, y_ls, y_calibrate = train_test_split(X_ls, y_ls, test_size=0.5, random_state=0)\n",
    "    X_eval, X_eval2, y_eval, y_eval2 = train_test_split(X_eval, y_eval, test_size=0.5, random_state=0)\n",
    "    \n",
    "    return X_ls, y_ls, X_calibrate, y_calibrate, X_eval, y_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2a7f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "## folktable data params\n",
    "\n",
    "dataset_name = 'Folktables'\n",
    "\n",
    "# residual score normalization \n",
    "l = 0\n",
    "u = 1217116"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6a8a02",
   "metadata": {},
   "source": [
    "## Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc6ba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_qr(X_model, y_model, quant):\n",
    "    qr = QuantileRegressor(quantile=quant, solver='highs')\n",
    "    qr.fit(X_model, y_model)\n",
    "    return qr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc2e4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_points(x):\n",
    "    return True\n",
    "\n",
    "def calibrate(x_input, y_input, bucket, r, delta, l, u, T, T_calibrate, myRLS):\n",
    "    n = bucket\n",
    "    r = r\n",
    "        \n",
    "    # no groups\n",
    "    groups = [all_points]\n",
    "\n",
    "    eta = 0.5\n",
    "    delta = delta\n",
    "\n",
    "    myUncertaintyQuantifier = MultiValidPrediction(delta, n, groups, eta, r)\n",
    "\n",
    "    myResidualCalibrationScorer = residualCalibrationScorer.ResidualCalibrationScorer()\n",
    "\n",
    "    myResidualCalibrationScorer.update(myRLS.predict)\n",
    "\n",
    "    y_input = np.asarray(y_input)\n",
    "\n",
    "    covered_arr = []\n",
    "    width_arr = []\n",
    "\n",
    "    for t in range(T):    \n",
    "\n",
    "        x_t = np.matrix(x_input[t])\n",
    "        y_t = y_input[t]\n",
    "\n",
    "        # calculate the new threshold \n",
    "        norm_q_t = myUncertaintyQuantifier.predict(x_t)\n",
    "        \n",
    "        # rescale threshold\n",
    "        q_t = norm_q_t * (u - l) + l\n",
    "\n",
    "        # check if the prediction set covers the data\n",
    "        curr_prediction_set = myResidualCalibrationScorer.get_prediction_set(x_t, q_t)\n",
    "        covered_t = curr_prediction_set.cover(np.matrix(y_t))\n",
    "        covered_arr.append(covered_t)\n",
    "\n",
    "        # get prediction interval width\n",
    "        width_arr.append(curr_prediction_set.interval_width)\n",
    "        \n",
    "        if (t > T_calibrate): # evaluate coverage / width after calibration data\n",
    "            covered_arr.append(covered_t)\n",
    "            width_arr.append(curr_prediction_set.interval_width)\n",
    "\n",
    "\n",
    "        # update the calibrator mutlivalidator \n",
    "        s_t = myResidualCalibrationScorer.calc_score(x_t, np.matrix(y_t))\n",
    "\n",
    "        # normalize score\n",
    "        norm_s_t = (s_t - l ) / (u - l)\n",
    "\n",
    "        myUncertaintyQuantifier.update(x_t, norm_q_t, norm_s_t)\n",
    "\n",
    "        # update the calibration scorer\n",
    "        myResidualCalibrationScorer.update(myRLS.predict)\n",
    "    \n",
    "    return covered_arr, width_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ea0f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_quantile(values, quantiles, sample_weight=None,   \n",
    "    values_sorted=False, old_style=False):\n",
    "    \"\"\" Very close to numpy.percentile, but supports weights.\n",
    "    NOTE: quantiles should be in [0, 1]!\n",
    "    :param values: numpy.array with data\n",
    "    :param quantiles: array-like with many quantiles needed\n",
    "    :param sample_weight: array-like of the same length as `array`\n",
    "    :param values_sorted: bool, if True, then will avoid sorting of\n",
    "        initial array\n",
    "    :param old_style: if True, will correct output to be consistent\n",
    "        with numpy.percentile.\n",
    "    :return: numpy.array with computed quantiles.\n",
    "    \"\"\"\n",
    "    values = np.array(values)\n",
    "    quantiles = np.array(quantiles)\n",
    "    if sample_weight is None:\n",
    "        sample_weight = np.ones(len(values))\n",
    "    sample_weight = np.array(sample_weight)\n",
    "    assert np.all(quantiles >= 0) and np.all(quantiles <= 1), \\\n",
    "        'quantiles should be in [0, 1]'\n",
    "\n",
    "    if not values_sorted:\n",
    "        sorter = np.argsort(values)\n",
    "        values = values[sorter]\n",
    "        sample_weight = sample_weight[sorter]\n",
    "\n",
    "    weighted_quantiles = np.cumsum(sample_weight) - 0.5 * sample_weight\n",
    "    if old_style:\n",
    "        # To be convenient with numpy.percentile\n",
    "        weighted_quantiles -= weighted_quantiles[0]\n",
    "        weighted_quantiles /= weighted_quantiles[-1]\n",
    "    else:\n",
    "        weighted_quantiles /= np.sum(sample_weight)\n",
    "    return np.interp(quantiles, weighted_quantiles, values)\n",
    "\n",
    "\n",
    "def do_weighted_conformal(x, y, weights, alpha, T, T_calibration, model):\n",
    "\n",
    "    # arrays for conformal prediction\n",
    "    width_conformal = []\n",
    "    cover_conformal = []\n",
    "    \n",
    "    myResidualCalibrationScorer = residualCalibrationScorer.ResidualCalibrationScorer()\n",
    "\n",
    "    y = np.asarray(y)\n",
    "\n",
    "\n",
    "    for t in range(T):\n",
    "        \n",
    "        x_t = np.matrix(x[t])\n",
    "        y_t = y[t]\n",
    "        \n",
    "        y_pred_conformal_t = model.predict(x_t)\n",
    "        myResidualCalibrationScorer.update(model.predict)\n",
    "        new_y = np.reshape(y, -1)\n",
    "        residuals = myResidualCalibrationScorer.calc_score(x, new_y)\n",
    "        calibration_size = len(x)\n",
    "\n",
    "        desired_quantile = np.ceil((1-alpha) * (calibration_size + 1)) / calibration_size\n",
    "        \n",
    "        w_t_conformal = weighted_quantile(residuals, (1-alpha), weights)\n",
    "\n",
    "        conformal_prediction_set = myResidualCalibrationScorer.get_prediction_set(x_t, w_t_conformal)\n",
    "\n",
    "        covered_conformal_t = conformal_prediction_set.cover(y_t)\n",
    "\n",
    "        if (t > T_calibration): # evaluate coverage / width after calibration data\n",
    "            width_conformal.append(w_t_conformal)\n",
    "            cover_conformal.append(covered_conformal_t)\n",
    "\n",
    "    return width_conformal, cover_conformal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209463b3",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Experimental parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57384c8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_trials = 1\n",
    "buckets = [40]\n",
    "d = 9\n",
    "\n",
    "# 1 - coverage\n",
    "alpha = .1\n",
    "\n",
    "model_name = 'Quantile Regression'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e103aa03",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3e5088",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../src')\n",
    "from MultiValidPrediction import MultiValidPrediction\n",
    "from calibrationScorers import residualCalibrationScorer\n",
    "import recursiveLeastSquares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731651cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each setting of number of buckets, we have num_trials coverage/width values\n",
    "folk_coverage = []\n",
    "folk_width = []\n",
    "\n",
    "folk_coverage_conf = []\n",
    "folk_width_conf = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2212a9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ls, y_ls, X_calibrate, y_calibrate, X_eval, y_eval = split_folk_data('CA', 'PA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c1b6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "conformal = True\n",
    "for num_bucket in buckets:\n",
    "    \n",
    "    trial_coverage = []\n",
    "    trial_width = []\n",
    "    trial_cov_conf = []\n",
    "    trial_width_conf = []\n",
    "    \n",
    "    for i in range(num_trials):\n",
    "        # split data\n",
    "        X_ls, y_ls, X_calibrate, y_calibrate, X_eval, y_eval = split_folk_data('CA', 'PA')\n",
    "\n",
    "        # train model\n",
    "        reg_model = train_qr(X_ls, y_ls, .5)\n",
    "\n",
    "        X = np.concatenate([X_calibrate, X_eval])\n",
    "        y = np.concatenate([y_calibrate, y_eval])\n",
    "        \n",
    "        # calibrate\n",
    "        coverage_res, width_res = calibrate(X, y, num_bucket, 80000, alpha, l, u, len(X), len(X_calibrate), reg_model)\n",
    "\n",
    "        # store average coverage and width for this trial\n",
    "        trial_coverage.append(np.mean(coverage_res))\n",
    "        trial_width.append(np.mean(width_res))\n",
    "        \n",
    "        # conformal\n",
    "        if conformal: # only do conformal once, not for each different setting of number of buckets\n",
    "            \n",
    "            # split conformal on shifted data\n",
    "            conf_width_res, conf_cov_res = do_weighted_conformal(X, y, (([1] * len(X))), alpha, len(X), len(X_calibrate), reg_model)\n",
    "\n",
    "            trial_cov_conf.append(np.mean(conf_cov_res))\n",
    "            trial_width_conf.append(np.mean(conf_width_res))\n",
    "\n",
    "\n",
    "    if conformal:\n",
    "        folk_coverage_conf.append(trial_cov_conf)\n",
    "        folk_width_conf.append(trial_width_conf)\n",
    "        conformal = False\n",
    "        \n",
    "    folk_coverage.append(trial_coverage)\n",
    "    folk_width.append(trial_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63977c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([folk_coverage[0], folk_coverage_conf[0]], label=['MVP', 'split conformal'])\n",
    "plt.legend()\n",
    "plt.title('Mean Coverage ({0} trials, target coverage .9) \\n {1} \\n {2}'.format(len(folk_coverage[0]), model_name, dataset_name))\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Coverage')\n",
    "plt.show()\n",
    "\n",
    "plt.hist([folk_width[0], folk_width_conf[0]], label=['MVP', 'split conformal'])\n",
    "plt.legend()\n",
    "plt.title('Median Width ({0} trials, target coverage .9) \\n {1} \\n {2}'.format(len(folk_coverage[0]), model_name, dataset_name))\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Interval Width (in $)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fdb795",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6354df43",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = open('folk-results/folk-coverage-conformal.pickle', 'rb')\n",
    "folk_coverage_conformal = p.load(fd)\n",
    "fd.close()\n",
    "\n",
    "fd = open('folk-results/folk-coverage.pickle', 'rb')\n",
    "folk_coverage = p.load(fd)\n",
    "fd.close()\n",
    "\n",
    "fd = open('folk-results/folk-width-conformal.pickle', 'rb')\n",
    "folk_width_conformal = p.load(fd)\n",
    "fd.close()\n",
    "\n",
    "fd = open('folk-results/folk-width.pickle', 'rb')\n",
    "folk_width = p.load(fd)\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47dfae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Quantile Regression'\n",
    "dataset_name = 'Folktables Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e4b62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0.87, 0.95, 60)\n",
    "plt.hist([folk_coverage[0]], label=['MVP'], color= 'blue', alpha = 0.4, linewidth=0.5, edgecolor = 'blue', bins=bins)\n",
    "plt.hist([folk_coverage_conformal[0]], label=['split conformal'], color= 'orange', alpha = 0.6, linewidth=0.5, edgecolor = 'orange', bins=bins)\n",
    "plt.legend()\n",
    "plt.axvline(x = .9, color = 'red', linestyle = '--', linewidth = 0.9)\n",
    "plt.title('Mean Coverage ({0} trials, target coverage .9) \\n {1} \\n {2}'.format(len(folk_coverage[0]), model_name, dataset_name))\n",
    "plt.ylabel('No. of Rounds')\n",
    "plt.xlabel('Mean Coverage')\n",
    "plt.xlim([.899, .96])\n",
    "plt.show()\n",
    "\n",
    "bins = np.linspace(72700, 73500, 60)\n",
    "plt.hist([folk_width[0]], label=['MVP'], color= 'blue', alpha = 0.4, linewidth=0.5, edgecolor = 'blue', bins=bins)\n",
    "plt.hist([folk_width_conformal[0]], label=['split conformal'], color= 'orange', alpha = 0.6, linewidth=0.5, edgecolor = 'orange', bins=bins)\n",
    "plt.legend()\n",
    "plt.legend()\n",
    "plt.title('Median Width ({0} trials, target coverage .9) \\n {1} \\n {2}'.format(len(folk_coverage[0]), model_name, dataset_name))\n",
    "plt.ylabel('No. Of Rounds')\n",
    "plt.xlabel('Median Interval Width (in $)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
