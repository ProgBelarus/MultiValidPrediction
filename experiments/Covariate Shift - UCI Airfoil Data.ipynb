{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bd5480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62778e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acd53bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## UCI Airfoil data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee1b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.read_csv(\"data/airfoil_self_noise.dat\", sep='\\t', header=None)\n",
    "\n",
    "full_data[0] = np.log(full_data[0])\n",
    "full_data[4] = np.log(full_data[4])\n",
    "\n",
    "dataset_name = 'UCI Airfoil'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef801b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append constant to all data as needed for LS implementation\n",
    "full_data.insert(0, \"constant\", [1] * len(full_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835bc007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def airfoil_split(data):\n",
    "    \"\"\"\n",
    "    Split airfoil data into separate folds for least squares data, calibration data, and evaluation data.\n",
    "\n",
    "    Returns:\n",
    "    ls_x, ls_y: data to train least squares model, 25% of full dataset\n",
    "    calibration_data: data to feed to calibration algorithm, 25% of full dataset\n",
    "    evaluation_data: data to feed to calibration algorithm and evaluate performance on, 50% of full dataset\n",
    "    xs_iid, ys_iid: concatenation of calibration_data and evaluation_data\n",
    "    \"\"\"\n",
    "    pre_train = data.sample(frac=.5, axis=0)\n",
    "\n",
    "    evaluation_data = data.drop(index=pre_train.index)\n",
    "\n",
    "    train_model = pre_train.sample(frac=.5, axis=0)\n",
    "\n",
    "    calibration_data = pre_train.drop(index=train_model.index)\n",
    "\n",
    "    ls_x = train_model.iloc[:, :6]\n",
    "    ls_y = train_model.iloc[:, 6:]\n",
    "\n",
    "    data_no_shift = pd.concat([calibration_data, evaluation_data])\n",
    "\n",
    "    xs_iid = data_no_shift.iloc[:, :6]\n",
    "    ys_iid = data_no_shift.iloc[:, 6:]\n",
    "    \n",
    "    return ls_x, ls_y, calibration_data, evaluation_data, xs_iid, ys_iid\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b86fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# residual conformal score normalization \n",
    "l = 0\n",
    "u = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c645537f",
   "metadata": {},
   "source": [
    "## Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b2045d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ls(x_model, y_model):\n",
    "    myRLS = recursiveLeastSquares.RLS(6, 1.0, 1)\n",
    "    ls_x = x_model.to_numpy()\n",
    "    ls_x = [np.matrix(x).T for x in ls_x]\n",
    "    ls_y = y_model.to_numpy()\n",
    "    ls_y = [y[0] for y in ls_y]\n",
    "    myRLS.fit(ls_x, ls_y)\n",
    "    return myRLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1552f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_points(x):\n",
    "    return True\n",
    "\n",
    "def calibrate(x_input, y_input, bucket, r, delta, l, u, T, T_calibrate, myRLS):\n",
    "    n = bucket\n",
    "    r = r\n",
    "        \n",
    "    groups = [all_points]\n",
    "\n",
    "    eta = np.sqrt(np.log(2 * len(groups) * n) / T)\n",
    "\n",
    "    delta = delta\n",
    "\n",
    "    myUncertaintyQuantifier = MultiValidPrediction(delta, n, groups, eta, r)\n",
    "\n",
    "    myResidualCalibrationScorer = residualCalibrationScorer.ResidualCalibrationScorer()\n",
    "\n",
    "    myResidualCalibrationScorer.update(myRLS.predict)\n",
    "    \n",
    "    y_input = np.asarray(y_input)\n",
    "\n",
    "    covered_arr = []\n",
    "    width_arr = []\n",
    "\n",
    "    for t in range(T):    \n",
    "        # data arrival\n",
    "        x_t = (x_input.iloc[t])\n",
    "        y_t = y_input[t]\n",
    "\n",
    "        # calculate the new threshold \n",
    "        norm_q_t = myUncertaintyQuantifier.predict(x_t)\n",
    "        \n",
    "        # rescale threshold\n",
    "        q_t = norm_q_t * (u - l) + l\n",
    "\n",
    "        # check if the prediction set covers the data\n",
    "        curr_prediction_set = myResidualCalibrationScorer.get_prediction_set(x_t, q_t)\n",
    "        covered_t = curr_prediction_set.cover(np.matrix(y_t))\n",
    "        covered_arr.append(covered_t)\n",
    "\n",
    "        # get prediction interval width\n",
    "        width_arr.append(curr_prediction_set.interval_width)\n",
    "        \n",
    "        if (t > T_calibrate): # evaluate coverage / width after calibration data\n",
    "            covered_arr.append(covered_t)\n",
    "            width_arr.append(curr_prediction_set.interval_width)\n",
    "\n",
    "\n",
    "        # update the calibrator mutlivalidator \n",
    "        s_t = myResidualCalibrationScorer.calc_score(x_t, np.matrix(y_t))\n",
    "\n",
    "        # normalize score\n",
    "        norm_s_t = (s_t - l ) / (u - l)\n",
    "\n",
    "        myUncertaintyQuantifier.update(x_t, norm_q_t, norm_s_t)\n",
    "\n",
    "        # update the calibration scorer\n",
    "        myResidualCalibrationScorer.update(myRLS.predict)\n",
    "    \n",
    "    return covered_arr, width_arr\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7a7b53",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bfb079",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../src')\n",
    "from MultiValidPrediction import MultiValidPrediction\n",
    "from calibrationScorers import residualCalibrationScorer\n",
    "import recursiveLeastSquares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf64638",
   "metadata": {},
   "source": [
    "## Experimental parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f4aa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## airfoil params\n",
    "num_trials = 500\n",
    "buckets = [40]\n",
    "d = 6\n",
    "\n",
    "# coverage\n",
    "alpha = .1\n",
    "\n",
    "model_name = 'Linear Regression'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722f85e4",
   "metadata": {},
   "source": [
    "## Data without covariate shift:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cadb251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each setting of number of buckets, we have num_trials coverage values\n",
    "no_shift_coverage = []\n",
    "no_shift_width = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cdebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_bucket in buckets:\n",
    "    \n",
    "    trial_coverage = []\n",
    "    trial_width = []\n",
    "    \n",
    "    for i in range(num_trials):\n",
    "        \n",
    "        # split data\n",
    "        ls_x, ls_y, calibration, evaluation, xs_iid, ys_iid = airfoil_split(full_data)        \n",
    "\n",
    "        # retrain LS\n",
    "        myRLS = train_ls(ls_x, ls_y)\n",
    "\n",
    "        # calibrate\n",
    "        coverage_res, width_res = calibrate(xs_iid, ys_iid, num_bucket, 1000, alpha, l, u, len(xs_iid), len(calibration), myRLS)\n",
    "\n",
    "        # store average coverage and width for this trial\n",
    "        trial_coverage.append(np.mean(coverage_res))\n",
    "        trial_width.append(np.median(width_res))\n",
    "    \n",
    "    no_shift_coverage.append(trial_coverage)\n",
    "    no_shift_width.append(trial_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e8af74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"without shifted data over {0} trials\\n\".format(num_trials))\n",
    "for i in range(len(buckets)):\n",
    "    print(\"coverage with {0} buckets is {1}\".format(buckets[i], np.mean(no_shift_coverage[i])))\n",
    "    print(\"width with {0} buckets is {1}\\n\".format(buckets[i], np.mean(no_shift_width[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195265e6",
   "metadata": {},
   "source": [
    "## Data with covariate shift: \n",
    "### Evaluating calibration on shifted data for us and oracle weights for weighted split conformal\n",
    "\n",
    "Here our comparison is a warm-start of our uncertainty prediction algorithm,\n",
    "by calibrating on data drawn from the shifted distribution we see at evalutation time, \n",
    "to simulate a fair comparison to weighted split conformal using likelihood ratios\n",
    "of the shifted evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21c27f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = [0, -1, 0, 0, 0, 1, 0] # weights for exponential tilting shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed4f031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each setting of number of buckets, we have num_trials coverage values\n",
    "shifted_coverage = []\n",
    "shifted_width = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a0c322",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_bucket in buckets:\n",
    "    \n",
    "    trial_coverage = []\n",
    "    trial_width = []\n",
    "    trial_cov_splitconf = []\n",
    "    trial_width_splitconf = []\n",
    "    \n",
    "    for i in range(num_trials):\n",
    "        \n",
    "        # split data\n",
    "        ls_x, ls_y, calibration, evaluation, xs_iid, ys_iid = airfoil_split(full_data)        \n",
    "        \n",
    "        # apply shift to evaluation data\n",
    "        beta = [0, -1, 0, 0, 0, 1, 0] # weights for shift\n",
    "        shift = evaluation.copy()\n",
    "        weight = np.exp(np.dot(shift, beta))\n",
    "        shift = shift.sample(frac=.25, axis=0, weights=weight, replace=True)\n",
    "                \n",
    "        weight = np.exp(np.dot(calibration, beta))\n",
    "        calibration = calibration.sample(frac=1, axis=0, weights=weight, replace=True)\n",
    "        \n",
    "        data_with_shift = pd.concat([calibration, shift])\n",
    "        xs_shift = data_with_shift.iloc[:, :6]\n",
    "        ys_shift = data_with_shift.iloc[:, 6:]\n",
    "    \n",
    "        # retrain LS\n",
    "        myRLS = train_ls(ls_x, ls_y)\n",
    "\n",
    "        # calibrate\n",
    "        coverage_res, width_res = calibrate(xs_shift, ys_shift, num_bucket, 1000, alpha, l, u, len(xs_shift), len(calibration), myRLS)\n",
    "\n",
    "        # store average coverage and width for this trial\n",
    "        trial_coverage.append(np.mean(coverage_res))\n",
    "        trial_width.append(np.median(width_res))\n",
    "\n",
    "        \n",
    "    shifted_coverage.append(trial_coverage)\n",
    "    shifted_width.append(trial_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad5379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"with shifted data over {0} trials\\n\".format(num_trials))\n",
    "for i in range(len(buckets)):\n",
    "    print(\"coverage with {0} buckets is {1}\".format(buckets[i], np.mean(shifted_coverage[i])))\n",
    "    print(\"width with {0} buckets is {1}\\n\".format(buckets[i], np.mean(shifted_width[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf50365",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04ca31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read mvp results\n",
    "shifted_coverage_res = np.array(pd.read_csv('airfoil-results/coverage-mvp.csv', header=None))\n",
    "shifted_width_res = np.array(pd.read_csv('airfoil-results/width-mvp.csv', header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c02e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read weighted split conformal results\n",
    "shifted_coverage_conf = pd.read_csv('airfoil-results/coverage-tibs.csv')\n",
    "shifted_coverage_conf = np.array(shifted_coverage_conf['x'])\n",
    "shifted_coverage_conf = np.random.choice(shifted_coverage_conf, 500, replace=False)\n",
    "shifted_width_conf = pd.read_csv('airfoil-results/width-tibs.csv')\n",
    "shifted_width_conf = np.array(shifted_width_conf['x'])\n",
    "shifted_width_conf = np.random.choice(shifted_width_conf, 500, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63351874",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'UCI Airfoil'\n",
    "model_name = 'Linear Regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29436f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0.775, 0.975, 40)\n",
    "plt.hist(shifted_coverage_res[0], label='MVP', color= 'blue', alpha = 0.4, linewidth=0.5, edgecolor = 'blue', bins=bins)\n",
    "plt.hist(shifted_coverage_conf, label='weighted split conformal', color= 'orange', alpha = 0.6, linewidth=0.5, edgecolor = 'orange', bins=bins)\n",
    "plt.legend()\n",
    "plt.axvline(x = .9, color = 'red', linestyle = '--', linewidth = 0.9)\n",
    "plt.title('Mean Coverage ({0} trials, target coverage .9) \\n {1} \\n {2} Data'.format(len(shifted_coverage_res[0]), model_name, dataset_name))\n",
    "plt.xlabel('Mean Coverage')\n",
    "plt.ylabel('No. of Rounds')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(shifted_width_res[0], label='MVP', color= 'blue', alpha = 0.4, linewidth=0.5, edgecolor = 'blue')\n",
    "plt.hist(shifted_width_conf, label='weighted split conformal', color= 'orange', alpha = 0.6, linewidth=0.5, edgecolor = 'orange')\n",
    "plt.legend()\n",
    "plt.title('Median Width ({0} trials, target coverage .9) \\n {1} \\n {2} Data'.format(len(shifted_coverage_res[0]), model_name, dataset_name))\n",
    "plt.xlabel('Median Interval Width (in decibels)')\n",
    "plt.ylabel('No. of Rounds')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
