{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23548,
     "status": "ok",
     "timestamp": 1648492251609,
     "user": {
      "displayName": "DaEto Georgy",
      "userId": "07578216823519586108"
     },
     "user_tz": 240
    },
    "id": "zAOPTJsJylLV",
    "outputId": "780637ec-b5ad-4bd7-8589-9da90bca9e46"
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join(os.getcwd(), '../src'))\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "\n",
    "import recursiveLeastSquares\n",
    "import splitConformalPrediction\n",
    "from MultiValidPrediction import MultiValidPrediction\n",
    "from calibrationScorers import residualCalibrationScorer, customResidualCalibrationScorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_group(feat_index, feat_value):\n",
    "    '''\n",
    "        Input: \n",
    "            - feat_index: index of desired input feature\n",
    "            - feat_value: desired value of that feature\n",
    "        Output:\n",
    "            - f - function which defines a group; f(x) returns True\n",
    "                  iff x[feat_index] == feat_value and returns False otherwise.\n",
    "    '''\n",
    "    def f(x):\n",
    "        return True if x[feat_index] == feat_value else False\n",
    "    \n",
    "    return f\n",
    "\n",
    "# Define group that includes all points\n",
    "def all_points(x):\n",
    "    return True\n",
    "\n",
    "basic_group = [all_points]\n",
    "\n",
    "# Define 20 overlapping sub-groups - each defined by the value of a single binary feature\n",
    "\n",
    "twenty_groups = list()\n",
    "num_groups = 0\n",
    "for i in range(10):\n",
    "    for j in range(2):\n",
    "        curr_group = produce_group(i, j)\n",
    "        twenty_groups.append(curr_group)\n",
    "\n",
    "num_groups = len(twenty_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Experiment with groups - Split-Conformal vs. MVP: Single trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set all parameters for a single trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1648492392939,
     "user": {
      "displayName": "DaEto Georgy",
      "userId": "07578216823519586108"
     },
     "user_tz": 240
    },
    "id": "mNqAcKetylLY"
   },
   "outputs": [],
   "source": [
    "# Parameters for our uncertainty quantifier\n",
    "T = 20000\n",
    "n = 40\n",
    "r = 80000000\n",
    "delta = 0.1\n",
    "K_e = 2.12\n",
    "\n",
    "eta = np.sqrt(np.log(num_groups * n) / (2 * K_e * num_groups * n))\n",
    "\n",
    "# Parameters for data generation\n",
    "x_std = 0.1\n",
    "y_std = 0.25\n",
    "d = 300 # choose d > 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generating data according to ordinary least-squares model - with one \"high-noise\" group and one \"low-noise\" group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1648492395061,
     "user": {
      "displayName": "DaEto Georgy",
      "userId": "07578216823519586108"
     },
     "user_tz": 240
    },
    "id": "yZXQudeJylLZ"
   },
   "outputs": [],
   "source": [
    "theta = np.random.normal(loc=np.zeros(d), scale=x_std)\n",
    "\n",
    "# d-dimension features - first 10 features are binary\n",
    "xs_binvars = np.random.randint(low = 0, high = 2, size = (T, 10))\n",
    "xs_remvars = np.random.normal(loc=np.zeros(d - 10), scale=x_std, size=(T, d - 10))\n",
    "xs = np.concatenate((xs_binvars, xs_remvars), axis = 1)\n",
    "std_dev_list = np.array([3.0, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1])\n",
    "std_dev = np.dot(xs_binvars, std_dev_list) + y_std\n",
    "ys = np.dot(xs, theta) + np.random.normal(loc=0, scale= std_dev, size=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initializing uncertainty-quantifiers and small initial calibration set for split-conformal prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 196,
     "status": "ok",
     "timestamp": 1648492431011,
     "user": {
      "displayName": "DaEto Georgy",
      "userId": "07578216823519586108"
     },
     "user_tz": 240
    },
    "id": "I0I7N5q7ylLg"
   },
   "outputs": [],
   "source": [
    "myUncertaintyQuantifier = MultiValidPrediction(delta, n, twenty_groups, eta, r, normalize_by_counts=True)\n",
    "myConformalPredictor = splitConformalPrediction.splitConformal(num_groups, twenty_groups, delta)\n",
    "myBasicConformalPredictor = splitConformalPrediction.splitConformal(1, basic_group, delta)\n",
    "myRLS_conformal = recursiveLeastSquares.RLS(d, 1.0, 1)\n",
    "myRLS_ours = recursiveLeastSquares.RLS(d, 1.0, 1)\n",
    "\n",
    "mult_factor = 8\n",
    "myResidualCalibrationScorer = customResidualCalibrationScorer.customResidualCalibrationScorer(mult_factor)\n",
    "\n",
    "# arrays for MVP\n",
    "q_array = []\n",
    "y_pred_ours_array = []\n",
    "covered_ours_array = []\n",
    "\n",
    "# arrays (per group) for MVP\n",
    "q_array_groups = [list() for i in range(num_groups)] \n",
    "y_pred_ours_groups = [list() for i in range(num_groups)] \n",
    "covered_ours_groups = [list() for i in range(num_groups)] \n",
    "\n",
    "# arrays for conformal prediction (with groups)\n",
    "y_pred_conformal_array = []\n",
    "w_t_conformal_array = []\n",
    "covered_conformal_array = []\n",
    "\n",
    "# arrays (per group) for conformal prediction (with groups)\n",
    "y_pred_conformal_groups = [list() for i in range(num_groups)]\n",
    "w_t_conformal_groups = [list() for i in range(num_groups)] \n",
    "covered_conformal_groups = [list() for i in range(num_groups)]\n",
    "\n",
    "\n",
    "# arrays for basic split-conformal (without groups)\n",
    "y_pred_basic_array = []\n",
    "w_t_basic_array = []\n",
    "covered_basic_array = []\n",
    "\n",
    "\n",
    "# array (per group) for basic split-conformal (without groups)\n",
    "y_pred_basic_groups = [list() for i in range(num_groups)]\n",
    "w_t_basic_groups = [list() for i in range(num_groups)]\n",
    "covered_basic_groups = [list() for i in range(num_groups)]\n",
    "\n",
    "# keep track of y values per group\n",
    "ys_groups = [list() for i in range(num_groups)]\n",
    "\n",
    "\n",
    "# Conformal warm-start calibration set using the same distribution. \n",
    "init_size = 10\n",
    "conformal_calibration_xs_binvars = np.random.randint(low = 0, high = 2, size = (init_size, 10))\n",
    "conformal_calibration_xs_remvars = np.random.normal(loc=np.zeros(d - 10), scale=x_std, size=(init_size, d - 10))\n",
    "xs_cc = np.concatenate((conformal_calibration_xs_binvars, conformal_calibration_xs_remvars), axis = 1)\n",
    "std_dev = np.dot(conformal_calibration_xs_binvars, std_dev_list) + y_std \n",
    "ys_cc = np.dot(xs_cc, theta) + np.random.normal(loc=0, scale= std_dev, size=init_size)\n",
    "\n",
    "for i, curr_y in enumerate(ys_cc):\n",
    "    curr_x = xs_cc[i]\n",
    "    myConformalPredictor.update_calibration_data(curr_x, curr_y)\n",
    "    myBasicConformalPredictor.update_calibration_data(curr_x, curr_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check if calibration data covers all groups. If it doesn't, run previous cell again (to generate new data) or try increasing init_size (size of warm-start calibration set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Does initial calibration data cover all groups: ' + str(myConformalPredictor.all_groups_covered()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Running MVP and split-conformal prediction across generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4106,
     "status": "ok",
     "timestamp": 1648492438701,
     "user": {
      "displayName": "DaEto Georgy",
      "userId": "07578216823519586108"
     },
     "user_tz": 240
    },
    "id": "-zxrB6ijylLh",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for t in range(T):\n",
    "    x_t = xs[t]\n",
    "    y_t = ys[t]\n",
    "    \n",
    "    # 1. CONFORMAL WITH GROUPS\n",
    "    \n",
    "    y_pred_conformal_t = myRLS_conformal.predict(x_t)\n",
    "    myResidualCalibrationScorer.update(myRLS_conformal.predict)\n",
    "    \n",
    "    w_t_conformal = myConformalPredictor.select_best_width(myResidualCalibrationScorer, x_t)\n",
    "    conformal_prediction_set = myResidualCalibrationScorer.get_prediction_set(x_t, w_t_conformal, mult_factor)\n",
    "    covered_conformal_t = conformal_prediction_set.cover(y_t)\n",
    "\n",
    "    w_t_basic = myBasicConformalPredictor.select_best_width(myResidualCalibrationScorer, x_t)\n",
    "    basic_prediction_set = myResidualCalibrationScorer.get_prediction_set(x_t, w_t_basic, mult_factor)\n",
    "    covered_basic_t = basic_prediction_set.cover(y_t)\n",
    "\n",
    "    if t % 2 == 0:\n",
    "        myConformalPredictor.update_calibration_data(x_t, y_t)\n",
    "        myBasicConformalPredictor.update_calibration_data(x_t, y_t)\n",
    "    else:\n",
    "        # update the linear regression model\n",
    "        myRLS_conformal.add_obs(x_t, y_t)\n",
    "\n",
    "    y_pred_conformal_array.append(y_pred_conformal_t)\n",
    "    w_t_conformal_array.append(mult_factor * w_t_conformal)\n",
    "    covered_conformal_array.append(covered_conformal_t)\n",
    "\n",
    "    y_pred_basic_array.append(y_pred_conformal_t)\n",
    "    w_t_basic_array.append(mult_factor * w_t_basic)\n",
    "    covered_basic_array.append(covered_basic_t)\n",
    "\n",
    "\n",
    "    # 2. MVP\n",
    "    y_pred_ours_t = myRLS_ours.predict(x_t)\n",
    "    myResidualCalibrationScorer.update(myRLS_ours.predict)\n",
    "\n",
    "    q_t = myUncertaintyQuantifier.predict(x_t)\n",
    "    curr_prediction_set = myResidualCalibrationScorer.get_prediction_set(x_t, q_t, mult_factor)\n",
    "\n",
    "    covered_ours_t = curr_prediction_set.cover(y_t)\n",
    "\n",
    "    s_t = myResidualCalibrationScorer.calc_score(x_t, y_t)\n",
    "\n",
    "    myRLS_ours.add_obs(x_t.T, y_t)\n",
    "    myUncertaintyQuantifier.update(x_t, q_t, s_t)\n",
    "\n",
    "    y_pred_ours_array.append(y_pred_ours_t)\n",
    "    q_array.append(mult_factor * q_t)\n",
    "    covered_ours_array.append(covered_ours_t)\n",
    "    \n",
    "    # Adding relevant values to specific groups to calculate performance metrics\n",
    "    for i in range(10):\n",
    "        for j in range(2):\n",
    "            # current group is feature i with value j\n",
    "            curr_index = (i * 2) + j\n",
    "            curr_group = twenty_groups[curr_index]\n",
    "            if curr_group(x_t):\n",
    "                ys_groups[curr_index].append(y_t)\n",
    "                y_pred_conformal_groups[curr_index].append(y_pred_conformal_t)\n",
    "                w_t_conformal_groups[curr_index].append(w_t_conformal)\n",
    "                covered_conformal_groups[curr_index].append(covered_conformal_t)\n",
    "                q_array_groups[curr_index].append(q_t)\n",
    "                y_pred_ours_groups[curr_index].append(y_pred_ours_t)\n",
    "                covered_ours_groups[curr_index].append(covered_ours_t)\n",
    "                y_pred_basic_groups[curr_index].append(y_pred_conformal_t)\n",
    "                w_t_basic_groups[curr_index].append(w_t_basic)\n",
    "                covered_basic_groups[curr_index].append(covered_basic_t)\n",
    "\n",
    "print('Trial complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Overall statistics (disregarding groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 159,
     "status": "ok",
     "timestamp": 1648492456525,
     "user": {
      "displayName": "DaEto Georgy",
      "userId": "07578216823519586108"
     },
     "user_tz": 240
    },
    "id": "14nVtTTIylLi",
    "outputId": "e9b0a906-d6b6-437d-e6d7-59344da30ca3"
   },
   "outputs": [],
   "source": [
    "y_pred_conformal_array = np.array(y_pred_conformal_array)\n",
    "w_t_conformal_array = np.array(w_t_conformal_array)\n",
    "\n",
    "y_pred_basic_array = np.array(y_pred_basic_array)\n",
    "w_t_basic_array = np.array(w_t_basic_array)\n",
    "\n",
    "y_pred_ours_array = np.array(y_pred_ours_array)\n",
    "q_array = np.array(q_array)\n",
    "\n",
    "print(\"*** COVERAGE ***\")\n",
    "print(\"Split-conformal (without groups): {0}\".format(np.average(covered_basic_array)))\n",
    "print(\"Split-conformal (with groups, conservative method): {0}\".format(np.average(covered_conformal_array)))\n",
    "print(\"MVP: {0}\".format(np.average(covered_ours_array)))\n",
    "print(\"\")\n",
    "\n",
    "print(\"*** WIDTH *** \")\n",
    "print(\"Split-conformal (without groups): {0}\".format(np.average(w_t_basic_array)))\n",
    "print(\"Split-conformal (with groups, conservative method): {0}\".format(np.average(w_t_conformal_array)))\n",
    "print(\"MVP: {0}\".format(np.average(q_array)))\n",
    "print(\"\")\n",
    "\n",
    "print(\"*** SQUARED LOSS ***\")\n",
    "squared_loss_basic = np.linalg.norm(ys - y_pred_basic_array)\n",
    "squared_loss_conformal = np.linalg.norm(ys - y_pred_conformal_array)\n",
    "squared_loss_ours = np.linalg.norm(ys - y_pred_ours_array)\n",
    "print(\"Split-conformal (without groups): {0}\".format(squared_loss_basic))\n",
    "print(\"Split-conformal (with groups, conservative method): {0}\".format(squared_loss_conformal))\n",
    "print(\"MVP: {0}\".format(squared_loss_ours))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plots (results across all groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting coverage across groups\n",
    "\n",
    "barWidth = 0.25\n",
    "br1 = np.arange(len(covered_ours_groups))\n",
    "br2 = [x + barWidth for x in br1]\n",
    "br3 = [x + barWidth for x in br2]\n",
    "\n",
    "coverage_conformal = [np.average(group) for group in covered_conformal_groups]\n",
    "coverage_ours = [np.average(group) for group in covered_ours_groups]\n",
    "coverage_basic = [np.average(group) for group in covered_basic_groups]\n",
    "\n",
    "plt.bar(br1, coverage_basic, color = 'b', width = barWidth, edgecolor = 'gray', label = 'Split-Conformal: Without groups', linewidth = 0.5)\n",
    "plt.bar(br2, coverage_conformal, color = 'm', width = barWidth, edgecolor = 'gray', label = 'Split-Conformal: With groups, conservative approach', linewidth = 0.5)\n",
    "plt.bar(br3, coverage_ours, color = 'c', width = barWidth, edgecolor = 'gray', label = 'Our Method', linewidth = 0.5)\n",
    "\n",
    "group_labels = [str(i) for i in range(num_groups)]\n",
    "plt.xticks([r + barWidth for r in range(len(covered_ours_groups))], group_labels)\n",
    "plt.axhline(y= 1 - delta, c = 'r', linewidth = 0.5)\n",
    "plt.text(19.55, 1 - delta + 0.02, '  desired')\n",
    "plt.text(19.55, 1 - delta - 0.04, '  coverage')\n",
    "plt.legend()\n",
    "plt.ylim([0.0,1.4])\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.xlabel('Groups')\n",
    "plt.ylabel('Average Coverage')\n",
    "plt.title('Comparison of group-wise coverage: Split-Conformal vs. MVP \\n')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting interval width across groups\n",
    "\n",
    "barWidth = 0.25\n",
    "br1 = np.arange(len(covered_ours_groups))\n",
    "br2 = [x + barWidth for x in br1]\n",
    "br3 = [x + barWidth for x in br2]\n",
    "\n",
    "width_conformal = [2 * mult_factor * np.average(group) for group in  w_t_conformal_groups]\n",
    "width_ours = [2 * mult_factor * np.average(group) for group in  q_array_groups]\n",
    "width_basic = [2 * mult_factor * np.average(group) for group in  w_t_basic_groups]\n",
    "\n",
    "plt.bar(br1, width_basic, color = 'b', width = barWidth, edgecolor = 'gray', label = 'Split-Conformal: Without groups', linewidth = 0.5)\n",
    "plt.bar(br2, width_conformal, color = 'm', width = barWidth, edgecolor = 'gray', label = 'Split-Conformal: With groups, conservative approach', linewidth = 0.5)\n",
    "plt.bar(br3, width_ours, color = 'c', width = barWidth, edgecolor = 'gray', label = 'MVP', linewidth = 0.5)\n",
    "group_labels = [str(i) for i in range(num_groups)]\n",
    "plt.xticks([r + barWidth for r in range(len(covered_ours_groups))], group_labels)\n",
    "plt.legend()\n",
    "plt.ylim([0.0,19.0])\n",
    "plt.title('Comparison of group-wise interval-width: Split-Conformal vs. MVP \\n')\n",
    "plt.xlabel('Groups')\n",
    "plt.ylabel('Average Interval Width')\n",
    "plt.savefig('width-mean-img.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Choose any specific group (defined by feature number and value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_feat = 0 # can be any i in [num_groups]\n",
    "feat_val = 1 # can be 0 or 1 (binary feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Statistics for specified group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = (group_feat * 2) + feat_val\n",
    "ys_group = ys_groups[index]\n",
    "\n",
    "y_pred_conformal_array_group = y_pred_conformal_groups[index]\n",
    "w_t_conformal_array_group = w_t_conformal_groups[index]\n",
    "y_pred_conformal_array_group = np.array(y_pred_conformal_array_group)\n",
    "w_t_conformal_array_group = np.array(w_t_conformal_array_group)\n",
    "\n",
    "y_pred_basic_array_group = y_pred_basic_groups[index]\n",
    "w_t_basic_array_group = w_t_basic_groups[index]\n",
    "y_pred_basic_array_group = np.array(y_pred_basic_array_group)\n",
    "w_t_basic_array_group = np.array(w_t_basic_array_group)\n",
    "\n",
    "y_pred_ours_array_group = y_pred_ours_groups[index]\n",
    "q_array_group = q_array_groups[index]\n",
    "y_pred_ours_array_group = np.array(y_pred_ours_array_group)\n",
    "q_array_group = np.array(q_array_group)\n",
    "\n",
    "covered_basic_array_group = covered_basic_groups[index]\n",
    "covered_conformal_array_group = covered_conformal_groups[index]\n",
    "covered_ours_array_group = covered_ours_groups[index]\n",
    "    \n",
    "print(\"======= CURRENT GROUP: FEATURE \" + str(group_feat) + \" = \" + str(feat_val) + \" =======\")\n",
    "print(\"*** COVERAGE ***\")\n",
    "print(\"Split-conformal (without): {0}\".format(np.average(covered_basic_array_group)))\n",
    "print(\"Split-conformal (with groups, conservative approach): {0}\".format(np.average(covered_conformal_array_group)))\n",
    "print(\"MVP: {0}\".format(np.average(covered_ours_array_group)))\n",
    "print(\"\")\n",
    "\n",
    "print(\"*** WIDTH *** \")\n",
    "print(\"Split-conformal (without): {0}\".format(np.average(w_t_basic_array_group)))\n",
    "print(\"Split-conformal (with groups, conservative approach): {0}\".format(np.average(w_t_conformal_array_group)))\n",
    "print(\"MVP: {0}\".format(np.average(q_array_group)))\n",
    "print(\"\")\n",
    "\n",
    "print(\"*** SQUARED LOSS ***\")\n",
    "squared_loss_basic = np.linalg.norm(ys_group - y_pred_basic_array_group)\n",
    "squared_loss_conformal = np.linalg.norm(ys_group - y_pred_conformal_array_group)\n",
    "squared_loss_ours = np.linalg.norm(ys_group - y_pred_ours_array_group)\n",
    "print(\"Split-conformal (without groups): {0}\".format(squared_loss_basic))\n",
    "print(\"Split-conformal (with groups, conservative approach): {0}\".format(squared_loss_conformal))\n",
    "print(\"MVP: {0}\".format(squared_loss_ours))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plots for specified group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting average coverage (conformal - basic) over time - for selected group\n",
    "covered_basic_over_time_group = [np.average(covered_basic_array_group[:t+1]) for t in range(len(covered_basic_array_group))]\n",
    "plt.plot(range(len(covered_basic_array_group)), covered_basic_over_time_group)\n",
    "plt.yticks(np.arange(0, 1.05, 0.05))\n",
    "plt.xlabel(\"No. of rounds\")\n",
    "plt.ylabel(\"Marginal coverage\")\n",
    "plt.axhline(y = 1 - delta, color = 'red', linestyle = '-', linewidth = 0.9)\n",
    "plt.text(len(covered_basic_array_group), 1 - delta + 0.01, '  desired coverage')\n",
    "plt.title(\"Coverage over time: Split-conformal (without groups)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 1769,
     "status": "ok",
     "timestamp": 1648492503363,
     "user": {
      "displayName": "DaEto Georgy",
      "userId": "07578216823519586108"
     },
     "user_tz": 240
    },
    "id": "yFvyxFTtylLk",
    "outputId": "bb24f7bf-a3b1-492e-ebc1-58fb1b615fba"
   },
   "outputs": [],
   "source": [
    "# Plotting average coverage (conformal) over time - for selected group\n",
    "covered_conformal_over_time_group = [np.average(covered_conformal_array_group[:t+1]) for t in range(len(covered_conformal_array_group))]\n",
    "plt.plot(range(len(covered_conformal_array_group)), covered_conformal_over_time_group)\n",
    "plt.yticks(np.arange(0, 1.05, 0.05))\n",
    "plt.xlabel(\"No. of rounds\")\n",
    "plt.ylabel(\"Marginal coverage\")\n",
    "plt.axhline(y = 1 - delta, color = 'red', linestyle = '-', linewidth = 0.9)\n",
    "plt.text(len(covered_conformal_array_group), 1 - delta + 0.01, '  desired coverage')\n",
    "plt.title(\"Coverage over time: Split-conformal (With groups, conservative approach)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 634,
     "status": "ok",
     "timestamp": 1648492529836,
     "user": {
      "displayName": "DaEto Georgy",
      "userId": "07578216823519586108"
     },
     "user_tz": 240
    },
    "id": "UxlLSpxEylLk",
    "outputId": "fe587ba7-0df5-4bf2-d995-f358ca6a5c35"
   },
   "outputs": [],
   "source": [
    "# Plotting average coverage(our method) over time - for chosen group\n",
    "covered_our_over_time_group = [np.average(covered_ours_array_group[:t+1]) for t in range(len(covered_ours_array_group))]\n",
    "plt.plot(range(len(covered_ours_array_group)), covered_our_over_time_group)\n",
    "plt.yticks(np.arange(0, 1.05, 0.05))\n",
    "plt.xlabel(\"No. of rounds\")\n",
    "plt.ylabel(\"Marginal coverage\")\n",
    "plt.axhline(y = 1 - delta, color = 'red', linestyle = '-', linewidth = 0.9)\n",
    "plt.text(len(covered_ours_array_group), 1 - delta + 0.01, '  desired coverage')\n",
    "plt.title(\"Coverage over time: MVP\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running several trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set all parameters and number of trials to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for our uncertainty quantifier\n",
    "T = 20000\n",
    "n = 40\n",
    "r = 80000000\n",
    "delta = 0.1\n",
    "K_e = 2.12\n",
    "\n",
    "eta = np.sqrt(np.log(num_groups * n) / (2 * K_e * num_groups * n))\n",
    "\n",
    "# data generation - constants\n",
    "x_std = 0.1\n",
    "y_std = 0.25\n",
    "d = 300 # choose d > 10\n",
    "mult_factor = 10\n",
    "std_dev_list = np.array([3.0, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1])\n",
    "\n",
    "# How many trials would you like to run?\n",
    "num_rounds = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Start trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_conformal_per_group_per_round = np.zeros((num_rounds, num_groups))\n",
    "coverage_ours_per_group_per_round = np.zeros((num_rounds, num_groups))\n",
    "coverage_basic_per_group_per_round = np.zeros((num_rounds, num_groups))\n",
    "width_conformal_per_group_per_round = np.zeros((num_rounds, num_groups))\n",
    "width_ours_per_group_per_round = np.zeros((num_rounds, num_groups))\n",
    "width_basic_per_group_per_round = np.zeros((num_rounds, num_groups))\n",
    "\n",
    "for k in range(num_rounds):\n",
    "    print('Running trial: ' + str(k))\n",
    "    \n",
    "    # data generation - random for each run\n",
    "    theta = np.random.normal(loc=np.zeros(d), scale=x_std)\n",
    "\n",
    "    # d-dimension features - first 10 features are binary\n",
    "    xs_binvars = np.random.randint(low = 0, high = 2, size = (T, 10))\n",
    "    xs_remvars = np.random.normal(loc=np.zeros(d - 10), scale=x_std, size=(T, d - 10))\n",
    "    xs = np.concatenate((xs_binvars, xs_remvars), axis = 1)\n",
    "    std_dev = np.dot(xs_binvars, std_dev_list) + y_std\n",
    "    ys = np.dot(xs, theta) + np.random.normal(loc=0, scale= std_dev, size=T)\n",
    "    \n",
    "    # Defining all uncertainty quantifiers and regressors\n",
    "\n",
    "    myUncertaintyQuantifier = MultiValidPrediction(delta, n, twenty_groups, eta, r, normalize_by_counts=True)\n",
    "    myConformalPredictor = splitConformalPrediction.splitConformal(num_groups, twenty_groups, delta)\n",
    "    myBasicConformalPredictor = splitConformalPrediction.splitConformal(1, basic_group, delta)\n",
    "    myRLS_conformal = recursiveLeastSquares.RLS(d, 1.0, 1)\n",
    "    myRLS_ours = recursiveLeastSquares.RLS(d, 1.0, 1)\n",
    "\n",
    "    myResidualCalibrationScorer = customResidualCalibrationScorer.customResidualCalibrationScorer(mult_factor)\n",
    "\n",
    "    # arrays for our method\n",
    "    q_array = []\n",
    "    y_pred_ours_array = []\n",
    "    covered_ours_array = []\n",
    "\n",
    "    # arrays (per group) for our method\n",
    "    q_array_groups = [list() for i in range(num_groups)] \n",
    "    y_pred_ours_groups = [list() for i in range(num_groups)] \n",
    "    covered_ours_groups = [list() for i in range(num_groups)] \n",
    "\n",
    "    # arrays for conformal prediction\n",
    "    y_pred_conformal_array = []\n",
    "    w_t_conformal_array = []\n",
    "    covered_conformal_array = []\n",
    "\n",
    "    # arrays (per group) for conformal prediction\n",
    "    y_pred_conformal_groups = [list() for i in range(num_groups)]\n",
    "    w_t_conformal_groups = [list() for i in range(num_groups)] \n",
    "    covered_conformal_groups = [list() for i in range(num_groups)]\n",
    "    \n",
    "    # arrays for basic method\n",
    "    y_pred_basic_array = []\n",
    "    w_t_basic_array = []\n",
    "    covered_basic_array = []\n",
    "    \n",
    "    # array (per group) for basic prediction\n",
    "    y_pred_basic_groups = [list() for i in range(num_groups)]\n",
    "    w_t_basic_groups = [list() for i in range(num_groups)]\n",
    "    covered_basic_groups = [list() for i in range(num_groups)]\n",
    "\n",
    "    # keep track of y values per group\n",
    "    ys_groups = [list() for i in range(num_groups)]\n",
    "\n",
    "\n",
    "    # Conformal warm-start calibration set using the same distribution. \n",
    "    init_size = 15\n",
    "    conformal_calibration_xs_binvars = np.random.randint(low = 0, high = 2, size = (init_size, 10))\n",
    "    conformal_calibration_xs_remvars = np.random.normal(loc=np.zeros(d - 10), scale=x_std, size=(init_size, d - 10))\n",
    "    xs_cc = np.concatenate((conformal_calibration_xs_binvars, conformal_calibration_xs_remvars), axis = 1)\n",
    "    std_dev = np.dot(conformal_calibration_xs_binvars, std_dev_list) + y_std\n",
    "    ys_cc = np.dot(xs_cc, theta) + np.random.normal(loc=0, scale= std_dev, size=init_size)\n",
    "\n",
    "    for i, curr_y in enumerate(ys_cc):\n",
    "        curr_x = xs_cc[i]\n",
    "        myConformalPredictor.update_calibration_data(curr_x, curr_y)\n",
    "        myBasicConformalPredictor.update_calibration_data(curr_x, curr_y)\n",
    "\n",
    "    print('Does initial calibration data cover all groups: ' + str(myConformalPredictor.all_groups_covered()))\n",
    "    # Run algorithm\n",
    "    \n",
    "    for t in range(T):\n",
    "        x_t = xs[t]\n",
    "        y_t = ys[t]\n",
    "        \n",
    "        # 1. SPLIT-CONFORMAL WITH AND WITHOUT GROUPS\n",
    "\n",
    "        y_pred_conformal_t = myRLS_conformal.predict(x_t)\n",
    "        myResidualCalibrationScorer.update(myRLS_conformal.predict)\n",
    "\n",
    "        w_t_conformal = myConformalPredictor.select_best_width(myResidualCalibrationScorer, x_t)\n",
    "        conformal_prediction_set = myResidualCalibrationScorer.get_prediction_set(x_t, w_t_conformal, mult_factor)\n",
    "\n",
    "        covered_conformal_t = conformal_prediction_set.cover(y_t)\n",
    "    \n",
    "        w_t_basic = myBasicConformalPredictor.select_best_width(myResidualCalibrationScorer, x_t)\n",
    "        basic_prediction_set = myResidualCalibrationScorer.get_prediction_set(x_t, w_t_basic, mult_factor)\n",
    "        \n",
    "        covered_basic_t = basic_prediction_set.cover(y_t)\n",
    "\n",
    "        if t % 2 == 0:\n",
    "            myConformalPredictor.update_calibration_data(x_t, y_t)\n",
    "            myBasicConformalPredictor.update_calibration_data(x_t, y_t)\n",
    "        else:\n",
    "            # update the linear regression model\n",
    "            myRLS_conformal.add_obs(x_t, y_t)\n",
    "\n",
    "        y_pred_conformal_array.append(y_pred_conformal_t)\n",
    "        w_t_conformal_array.append(mult_factor * w_t_conformal)\n",
    "        covered_conformal_array.append(covered_conformal_t)\n",
    "        \n",
    "        y_pred_basic_array.append(y_pred_conformal_t)\n",
    "        w_t_basic_array.append(mult_factor * w_t_basic)\n",
    "        covered_basic_array.append(covered_basic_t)\n",
    "\n",
    "\n",
    "        # 2. MVP\n",
    "        y_pred_ours_t = myRLS_ours.predict(x_t)\n",
    "        myResidualCalibrationScorer.update(myRLS_ours.predict)\n",
    "\n",
    "        q_t = myUncertaintyQuantifier.predict(x_t)\n",
    "        curr_prediction_set = myResidualCalibrationScorer.get_prediction_set(x_t, q_t, mult_factor)\n",
    "\n",
    "        covered_ours_t = curr_prediction_set.cover(y_t)\n",
    "\n",
    "        s_t = myResidualCalibrationScorer.calc_score(x_t, y_t)\n",
    "\n",
    "        myRLS_ours.add_obs(x_t.T, y_t)\n",
    "        myUncertaintyQuantifier.update(x_t, q_t, s_t)\n",
    "\n",
    "        y_pred_ours_array.append(y_pred_ours_t)\n",
    "        q_array.append(mult_factor * q_t)\n",
    "        covered_ours_array.append(covered_ours_t)\n",
    "\n",
    "        # Adding relevant values to specific groups\n",
    "        for i in range(10):\n",
    "            for j in range(2):\n",
    "                # current group is feature i with value j\n",
    "                curr_index = (i * 2) + j\n",
    "                curr_group = twenty_groups[curr_index]\n",
    "                if curr_group(x_t):\n",
    "                    ys_groups[curr_index].append(y_t)\n",
    "                    y_pred_conformal_groups[curr_index].append(y_pred_conformal_t)\n",
    "                    w_t_conformal_groups[curr_index].append(w_t_conformal)\n",
    "                    covered_conformal_groups[curr_index].append(covered_conformal_t)\n",
    "                    q_array_groups[curr_index].append(q_t)\n",
    "                    y_pred_ours_groups[curr_index].append(y_pred_ours_t)\n",
    "                    covered_ours_groups[curr_index].append(covered_ours_t)\n",
    "                    y_pred_basic_groups[curr_index].append(y_pred_conformal_t)\n",
    "                    w_t_basic_groups[curr_index].append(w_t_basic)\n",
    "                    covered_basic_groups[curr_index].append(covered_basic_t)\n",
    "    \n",
    "    y_pred_conformal_array = np.array(y_pred_conformal_array)\n",
    "    w_t_conformal_array = np.array(w_t_conformal_array)\n",
    "    w_t_basic_array = np.array(w_t_basic_array)\n",
    "\n",
    "    y_pred_ours_array = np.array(y_pred_ours_array)\n",
    "    q_array = np.array(q_array)\n",
    "    \n",
    "    coverage_conformal = [np.average(group) for group in covered_conformal_groups]\n",
    "    coverage_ours = [np.average(group) for group in covered_ours_groups]\n",
    "    coverage_basic = [np.average(group) for group in covered_basic_groups]\n",
    "    \n",
    "    width_conformal = [2 * mult_factor * np.average(group) for group in  w_t_conformal_groups]\n",
    "    width_ours = [2 * mult_factor * np.average(group) for group in  q_array_groups]\n",
    "    width_basic = [2 * mult_factor * np.average(group) for group in w_t_basic_groups]\n",
    "    \n",
    "    coverage_conformal_per_group_per_round[k] = coverage_conformal\n",
    "    coverage_ours_per_group_per_round[k] = coverage_ours\n",
    "    coverage_basic_per_group_per_round[k] = coverage_basic\n",
    "    \n",
    "    width_conformal_per_group_per_round[k] = width_conformal\n",
    "    width_ours_per_group_per_round[k] = width_ours\n",
    "    width_basic_per_group_per_round[k] = width_basic\n",
    "    \n",
    "print('All trials complete')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plots for statistics across groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting average coverage across all rounds for all groups\n",
    "\n",
    "coverage_conformal_across_rounds = np.mean(coverage_conformal_per_group_per_round, axis = 0)\n",
    "coverage_ours_across_rounds = np.mean(coverage_ours_per_group_per_round, axis = 0)\n",
    "coverage_basic_across_rounds = np.mean(coverage_basic_per_group_per_round, axis = 0)\n",
    "\n",
    "barWidth = 0.25\n",
    "br1 = np.arange(len(coverage_ours_across_rounds))\n",
    "br2 = [x + barWidth for x in br1]\n",
    "br3 = [x + barWidth for x in br2]\n",
    "\n",
    "plt.bar(br1, coverage_basic_across_rounds, color = 'b', width = barWidth, edgecolor = 'gray', label = 'Split-Conformal: Without groups', linewidth = 0.5)\n",
    "plt.bar(br2, coverage_conformal_across_rounds, color = 'm', width = barWidth, edgecolor = 'gray', label = 'Split-Conformal: With groups, conservative approach', linewidth = 0.5)\n",
    "plt.bar(br3, coverage_ours_across_rounds, color = 'c', width = barWidth, edgecolor = 'gray', label = 'MVP', linewidth = 0.5)\n",
    "group_labels = [str(i) for i in range(num_groups)]\n",
    "plt.xticks([r + barWidth for r in range(len(coverage_ours_across_rounds))], group_labels)\n",
    "plt.axhline(y= 1 - delta, c = 'r', linewidth = 0.5)\n",
    "plt.text(19.55, 1 - delta + 0.02, '  desired')\n",
    "plt.text(19.55, 1 - delta - 0.04, '  coverage')\n",
    "plt.legend()\n",
    "plt.ylim([0.0,1.4])\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.title('Comparison of group-wise coverage: Split-Conformal vs. MVP \\n')\n",
    "plt.xlabel('Groups')\n",
    "plt.ylabel('Average Coverage')\n",
    "# plt.savefig('coverage-mean.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting average interval width across all rounds for all groups\n",
    "\n",
    "width_conformal_across_rounds = np.mean(width_conformal_per_group_per_round, axis = 0)\n",
    "width_ours_across_rounds = np.mean(width_ours_per_group_per_round, axis = 0)\n",
    "width_basic_across_rounds = np.mean(width_basic_per_group_per_round, axis = 0)\n",
    "\n",
    "barWidth = 0.25\n",
    "br1 = np.arange(len(coverage_ours_across_rounds))\n",
    "br2 = [x + barWidth for x in br1]\n",
    "br3 = [x + barWidth for x in br2]\n",
    "\n",
    "plt.bar(br1, width_basic_across_rounds, color = 'b', width = barWidth, edgecolor = 'gray', label = 'Split-Conformal: Without groups', linewidth = 0.5)\n",
    "plt.bar(br2, width_conformal_across_rounds, color = 'm', width = barWidth, edgecolor = 'gray', label = 'Split-Conformal: With groups, conservative approach', linewidth = 0.5)\n",
    "plt.bar(br3, width_ours_across_rounds, color = 'c', width = barWidth, edgecolor = 'gray', label = 'MVP', linewidth = 0.5)\n",
    "group_labels = [str(i) for i in range(num_groups)]\n",
    "plt.xticks([r + barWidth for r in range(len(coverage_ours_across_rounds))], group_labels)\n",
    "plt.legend()\n",
    "plt.ylim([0.0,19.0])\n",
    "plt.title('Comparison of group-wise interval-width: Split-Conformal vs. MVP \\n')\n",
    "plt.xlabel('Groups')\n",
    "plt.ylabel('Average Interval Width')\n",
    "# plt.savefig('width-mean.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting median coverage across all rounds for all groups, along with 25th to 75th quantile bar\n",
    "\n",
    "coverage_conformal_across_rounds = np.median(coverage_conformal_per_group_per_round, axis = 0)\n",
    "coverage_ours_across_rounds = np.median(coverage_ours_per_group_per_round, axis = 0)\n",
    "coverage_basic_across_rounds = np.median(coverage_basic_per_group_per_round, axis = 0)\n",
    "\n",
    "coverage_conformal_across_rounds_mean = np.mean(coverage_conformal_per_group_per_round, axis = 0)\n",
    "coverage_ours_across_rounds_mean = np.mean(coverage_ours_per_group_per_round, axis = 0)\n",
    "coverage_basic_across_rounds_mean = np.mean(coverage_basic_per_group_per_round, axis = 0)\n",
    "\n",
    "coverage_conformal_25_quantile = np.quantile(coverage_conformal_per_group_per_round, 0.25, axis = 0)\n",
    "coverage_ours_25_quantile = np.quantile(coverage_ours_per_group_per_round, 0.25, axis = 0)\n",
    "coverage_basic_25_quantile = np.quantile(coverage_basic_per_group_per_round, 0.25, axis = 0)\n",
    "coverage_conformal_75_quantile = np.quantile(coverage_conformal_per_group_per_round, 0.75, axis = 0)\n",
    "coverage_ours_75_quantile = np.quantile(coverage_ours_per_group_per_round, 0.75, axis = 0)\n",
    "coverage_basic_75_quantile = np.quantile(coverage_basic_per_group_per_round, 0.75, axis = 0)\n",
    "\n",
    "barWidth = 0.25\n",
    "br1 = np.arange(len(coverage_ours_across_rounds))\n",
    "br2 = [x + barWidth for x in br1]\n",
    "br3 = [x + barWidth for x in br2]\n",
    "\n",
    "for k, val in enumerate(br1):\n",
    "    plt.vlines(x = val, ymin = coverage_basic_25_quantile[k], ymax = coverage_basic_75_quantile[k], color = 'black', linewidth = 0.6)\n",
    "\n",
    "for i, val in enumerate(br2):\n",
    "    plt.vlines(x = val, ymin = coverage_conformal_25_quantile[i], ymax = coverage_conformal_75_quantile[i], color = 'black', linewidth = 0.6)    \n",
    "\n",
    "for j, val in enumerate(br3):\n",
    "    plt.vlines(x = val, ymin = coverage_ours_25_quantile[j], ymax = coverage_ours_75_quantile[j], color = 'black', linewidth = 0.6)\n",
    "\n",
    "plt.bar(br1, coverage_basic_across_rounds, color = 'b', width = barWidth, edgecolor = 'gray', label = 'Split-Conformal: Without groups', linewidth = 0.4, alpha = 0.6)\n",
    "plt.bar(br2, coverage_conformal_across_rounds, color = 'm', width = barWidth, edgecolor = 'gray', label = 'Split-Conformal: With groups, conservative approach', linewidth = 0.4, alpha =0.6)\n",
    "plt.bar(br3, coverage_ours_across_rounds, color = 'c', width = barWidth, edgecolor = 'gray', label = 'MVP', linewidth = 0.4, alpha = 0.6)\n",
    "group_labels = [str(i) for i in range(num_groups)]\n",
    "plt.xticks([r + barWidth for r in range(len(coverage_ours_across_rounds))], group_labels)\n",
    "plt.axhline(y= 1 - delta, c = 'r', linewidth = 0.5)\n",
    "plt.text(19.55, 1 - delta + 0.02, '  desired')\n",
    "plt.text(19.55, 1 - delta - 0.04, '  coverage')\n",
    "plt.legend()\n",
    "plt.ylim([0.0,1.5])\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.xlabel('Groups')\n",
    "plt.ylabel('Coverage (Median)')\n",
    "plt.title('Comparison of group-wise coverage: Split-Conformal vs. MVP \\n')\n",
    "# plt.savefig('../../coverage-median.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting median interval width across all rounds for all groups, along with 25th to 75th quantile bar\n",
    "\n",
    "width_conformal_across_rounds = np.median(width_conformal_per_group_per_round, axis = 0)\n",
    "width_ours_across_rounds = np.median(width_ours_per_group_per_round, axis = 0)\n",
    "width_basic_across_round = np.median(width_basic_per_group_per_round, axis = 0)\n",
    "\n",
    "width_conformal_25_quantile = np.quantile(width_conformal_per_group_per_round, 0.25, axis = 0)\n",
    "width_ours_25_quantile = np.quantile(width_ours_per_group_per_round, 0.25, axis = 0)\n",
    "width_basic_25_quantile = np.quantile(width_basic_per_group_per_round, 0.25, axis = 0)\n",
    "width_conformal_75_quantile = np.quantile(width_conformal_per_group_per_round, 0.75, axis = 0)\n",
    "width_ours_75_quantile = np.quantile(width_ours_per_group_per_round, 0.75, axis = 0)\n",
    "width_basic_75_quantile = np.quantile(width_basic_per_group_per_round, 0.75, axis = 0)\n",
    "    \n",
    "barWidth = 0.25\n",
    "br1 = np.arange(len(width_conformal_across_rounds))\n",
    "br2 = [x + barWidth for x in br1]\n",
    "br3 = [x + barWidth for x in br2]\n",
    "\n",
    "for k, val in enumerate(br1):\n",
    "    plt.vlines(x = val, ymin = width_basic_25_quantile[k], ymax = width_basic_75_quantile[k], color = 'black', linewidth = 0.6)\n",
    "    \n",
    "for i, val in enumerate(br2):\n",
    "    plt.vlines(x = val, ymin = width_conformal_25_quantile[i], ymax = width_conformal_75_quantile[i], color = 'black', linewidth = 0.6)\n",
    "\n",
    "for j, val in enumerate(br3):\n",
    "    plt.vlines(x = val, ymin = width_ours_25_quantile[j], ymax = width_ours_75_quantile[j], color = 'black', linewidth = 0.6)\n",
    "    \n",
    "plt.bar(br1, width_basic_across_round, color = 'b', width = barWidth, edgecolor = 'gray', label = 'Split-Conformal: Without groups', linewidth = 0.4, alpha = 0.6)\n",
    "plt.bar(br2, width_conformal_across_rounds, color = 'm', width = barWidth, edgecolor = 'gray', label = 'Split-Conformal: With groups, conservative approach', linewidth = 0.4, alpha = 0.6)\n",
    "plt.bar(br3, width_ours_across_rounds, color = 'c', width = barWidth, edgecolor = 'gray', label = 'MVP', linewidth = 0.4, alpha = 0.6)\n",
    "group_labels = [str(i) for i in range(num_groups)]\n",
    "plt.xticks([r + barWidth for r in range(len(covered_ours_groups))], group_labels)\n",
    "plt.legend()\n",
    "plt.ylim([0.0,20.0])\n",
    "plt.title('Comparison of group-wise interval-width: Split-Conformal vs. MVP \\n')\n",
    "plt.xlabel('Groups')\n",
    "plt.ylabel('Interval Width (Median)')\n",
    "# plt.savefig('../../width-median.pdf')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Linear Regression Experiment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
